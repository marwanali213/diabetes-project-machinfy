{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c75982e6-e51e-4156-8478-cd7617f7d9c9",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, accuracy_score, \n",
    "                           precision_recall_fscore_support, roc_auc_score, roc_curve)\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv(\"Data/Multiclass Diabetes Dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfece619-da55-41d8-9ea0-6f344cb44453",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    df_feat = df.copy()\n",
    "    \n",
    "    # Log transformations for skewed features\n",
    "    df_feat['Urea_log'] = np.log1p(df['Urea'])\n",
    "    df_feat['Cr_log'] = np.log1p(df['Cr'])\n",
    "    df_feat['VLDL_log'] = np.log1p(df['VLDL'])\n",
    "    df_feat['TG_log'] = np.log1p(df['TG'])\n",
    "    \n",
    "    # Risk indicators based on medical thresholds\n",
    "    df_feat['HbA1c_Risk'] = (df['HbA1c'] >= 6.5).astype(int)\n",
    "    df_feat['BMI_Risk'] = (df['BMI'] >= 30).astype(int)\n",
    "    df_feat['Age_Risk'] = (df['AGE'] >= 45).astype(int)\n",
    "    df_feat['TG_Risk'] = (df['TG'] > 150).astype(int)\n",
    "    df_feat['Chol_Risk'] = (df['Chol'] > 200).astype(int)\n",
    "    \n",
    "    # Composite risk score\n",
    "    df_feat['Total_Risk_Score'] = (df_feat['HbA1c_Risk'] + df_feat['BMI_Risk'] + \n",
    "                                   df_feat['Age_Risk'] + df_feat['TG_Risk'] + \n",
    "                                   df_feat['Chol_Risk'])\n",
    "    \n",
    "    # Ratios\n",
    "    df_feat['Chol_HDL_Ratio'] = df['Chol'] / (df['HDL'] + 1e-5)\n",
    "    df_feat['LDL_HDL_Ratio'] = df['LDL'] / (df['HDL'] + 1e-5)\n",
    "    df_feat['TG_HDL_Ratio'] = df['TG'] / (df['HDL'] + 1e-5)\n",
    "    \n",
    "    return df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f12a100b-abb0-4963-b524-5afe09e6a664",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (264, 22)\n",
      "Target distribution:\n",
      "Class\n",
      "2    128\n",
      "0     96\n",
      "1     40\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_enhanced = create_features(df)\n",
    "\n",
    "# Select features for modeling\n",
    "# Based on ANOVA results, excluding HDL and LDL as they showed no significance\n",
    "feature_columns = ['Gender', 'AGE', 'Urea', 'Cr', 'HbA1c', 'Chol', 'TG', 'VLDL', 'BMI',\n",
    "                  'Urea_log', 'Cr_log', 'VLDL_log', 'TG_log',\n",
    "                  'HbA1c_Risk', 'BMI_Risk', 'Age_Risk', 'TG_Risk', 'Chol_Risk',\n",
    "                  'Total_Risk_Score', 'Chol_HDL_Ratio', 'LDL_HDL_Ratio', 'TG_HDL_Ratio']\n",
    "\n",
    "X = df_enhanced[feature_columns]\n",
    "y = df_enhanced['Class']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6c4c746-ee7a-4fa9-95fb-d34f98fca5c8",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3. Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create dataframes for easier handling\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=feature_columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bc5a5a9-7ba1-4e26-8ef8-9549c7d50bde",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MODEL DEVELOPMENT ===\n",
      "\n",
      "Logistic Regression:\n",
      "  CV Accuracy: 0.9193 (+/- 0.0577)\n",
      "  Test Accuracy: 0.9245\n",
      "Random Forest:\n",
      "  CV Accuracy: 0.9762 (+/- 0.0426)\n",
      "  Test Accuracy: 0.9623\n",
      "Gradient Boosting:\n",
      "  CV Accuracy: 0.9526 (+/- 0.0522)\n",
      "  Test Accuracy: 0.9623\n",
      "XGBoost:\n",
      "  CV Accuracy: 0.9620 (+/- 0.0775)\n",
      "  Test Accuracy: 0.9811\n",
      "SVM:\n",
      "  CV Accuracy: 0.8388 (+/- 0.0565)\n",
      "  Test Accuracy: 0.9245\n",
      "KNN:\n",
      "  CV Accuracy: 0.7960 (+/- 0.1618)\n",
      "  Test Accuracy: 0.8868\n",
      "Decision Tree:\n",
      "  CV Accuracy: 0.9480 (+/- 0.0461)\n",
      "  Test Accuracy: 0.9434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\LapTop\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "  File \"C:\\Users\\LapTop\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py\", line 503, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "  File \"C:\\Users\\LapTop\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py\", line 971, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Users\\LapTop\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py\", line 1456, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n"
     ]
    }
   ],
   "source": [
    "print(\"=== MODEL DEVELOPMENT ===\\n\")\n",
    "\n",
    "# 4. Define models to evaluate\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(multi_class='multinomial', max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBClassifier(objective='multi:softmax', num_class=3, random_state=42),\n",
    "    'SVM': SVC(kernel='rbf', probability=True, random_state=42),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42)\n",
    "}\n",
    "results = {}\n",
    "cv_scores = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Cross-validation\n",
    "    cv_score = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "    cv_scores[name] = cv_score\n",
    "    \n",
    "    # Train and evaluate\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'predictions': y_pred,\n",
    "        'accuracy': accuracy,\n",
    "        'cv_mean': cv_score.mean(),\n",
    "        'cv_std': cv_score.std()\n",
    "    }\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  CV Accuracy: {cv_score.mean():.4f} (+/- {cv_score.std() * 2:.4f})\")\n",
    "    print(f\"  Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e20afc01-a879-4cac-875b-138d5472714b",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model based on CV: Random Forest\n"
     ]
    }
   ],
   "source": [
    "best_model_name = max(results.keys(), key=lambda x: results[x]['cv_mean'])\n",
    "print(f\"\\nBest model based on CV: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df867ce3-8a06-4421-9c2b-e815bf6abda8",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== HYPERPARAMETER TUNING ===\n",
      "\n",
      "Tuning Random Forest...\n",
      "  Best parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "  Best CV score: 0.9810\n",
      "Tuning XGBoost...\n",
      "  Best parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\n",
      "  Best CV score: 0.9620\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== HYPERPARAMETER TUNING ===\\n\")\n",
    "\n",
    "# Sort models by CV performance\n",
    "sorted_models = sorted(results.items(), key=lambda x: x[1]['cv_mean'], reverse=True)[:3]\n",
    "\n",
    "# Define parameter grids\n",
    "param_grids = {\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.3],\n",
    "        'subsample': [0.8, 1.0]\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.3],\n",
    "        'subsample': [0.8, 1.0]\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'solver': ['newton-cg', 'lbfgs', 'saga']\n",
    "    }\n",
    "}\n",
    "\n",
    "best_tuned_model = None\n",
    "best_tuned_score = 0\n",
    "\n",
    "for model_name, model_results in sorted_models[:2]:  # Tune top 2 models\n",
    "    if model_name in param_grids:\n",
    "        print(f\"Tuning {model_name}...\")\n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            models[model_name],\n",
    "            param_grids[model_name],\n",
    "            cv=5,\n",
    "            scoring='accuracy',\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        print(f\"  Best parameters: {grid_search.best_params_}\")\n",
    "        print(f\"  Best CV score: {grid_search.best_score_:.4f}\")\n",
    "        \n",
    "        if grid_search.best_score_ > best_tuned_score:\n",
    "            best_tuned_score = grid_search.best_score_\n",
    "            best_tuned_model = grid_search.best_estimator_\n",
    "            best_tuned_name = model_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "893e18e2-f8b8-4d37-9dec-52f3249fabef",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FINAL MODEL EVALUATION ===\n",
      "\n",
      "Best Model: Random Forest\n",
      "\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Non-Diabetic       0.95      1.00      0.97        19\n",
      "        Diabetic       1.00      1.00      1.00         8\n",
      "Predict-Diabetic       1.00      0.96      0.98        26\n",
      "\n",
      "        accuracy                           0.98        53\n",
      "       macro avg       0.98      0.99      0.98        53\n",
      "    weighted avg       0.98      0.98      0.98        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== FINAL MODEL EVALUATION ===\\n\")\n",
    "\n",
    "# Use the best tuned model\n",
    "final_model = best_tuned_model\n",
    "final_model.fit(X_train_scaled, y_train)\n",
    "y_pred_final = final_model.predict(X_test_scaled)\n",
    "y_pred_proba = final_model.predict_proba(X_test_scaled)\n",
    "\n",
    "print(f\"Best Model: {best_tuned_name}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_final, \n",
    "                          target_names=['Non-Diabetic', 'Diabetic', 'Predict-Diabetic']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6eff0504-e625-489e-8afb-bb84e8fb3c55",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['diabetes_scaler.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model and scaler\n",
    "joblib.dump(final_model, 'diabetes_multiclass_model.pkl')\n",
    "joblib.dump(scaler, 'diabetes_scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b24fb74-458c-4543-ba29-74e428ba9576",
   "metadata": {
    "include-cell-in-app": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
